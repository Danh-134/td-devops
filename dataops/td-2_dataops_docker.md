Parfait ğŸ‘
Voici **les deux livrables**, sÃ©parÃ©s comme demandÃ© :

1. **TD Docker DataOps â€“ version Ã©tudiant (clÃ© en main)**
2. **Fiche enseignant (corrigÃ© + objectifs pÃ©dagogiques cachÃ©s)**

Tu peux les mettre dans ton repo sous deux fichiers distincts.

---

# ğŸ§ª TD DataOps â€“ Docker & Pipelines de DonnÃ©es

## ğŸ¯ Objectifs du TD

Ã€ lâ€™issue de ce TD, vous serez capables de :

* Comprendre le rÃ´le de **Docker en DataOps**
* Construire un **pipeline de donnÃ©es reproductible**
* SÃ©parer **donnÃ©es, code et environnement**
* Comprendre pourquoi Docker est critique pour la fiabilitÃ© des pipelines data

---

## ğŸ§  Rappel : Docker en DataOps

En DataOps, Docker permet de :

* garantir que les pipelines tournent **dans le mÃªme environnement**
* Ã©viter les problÃ¨mes de versions (Python, librairies)
* exÃ©cuter les traitements data **de maniÃ¨re reproductible**

> ğŸ’¡ Un pipeline DataOps doit produire **le mÃªme rÃ©sultat**, peu importe la machine.

---

## ğŸ“ Structure du projet

```mermaid
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ sales.csv
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ sales_clean.csv
â”œâ”€â”€ src/
â”‚   â””â”€â”€ clean_data.py
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_data_quality.py
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

## ğŸ§ª Partie 1 â€“ Pipeline de donnÃ©es simple

### 1ï¸âƒ£ Script de transformation

`src/clean_data.py` :

```python
import pandas as pd

df = pd.read_csv("data/raw/sales.csv")

df_clean = df.dropna()
df_clean = df_clean[df_clean["price"] > 0]

df_clean.to_csv("data/processed/sales_clean.csv", index=False)
```

ğŸ“Œ **Question**
Pourquoi cette transformation doit-elle Ãªtre dÃ©terministe ?

---

## ğŸ§ª Partie 2 â€“ Dockerisation du pipeline DataOps

### 2ï¸âƒ£ Dockerfile

CrÃ©ez un fichier `Dockerfile` :

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY src/ src/
COPY tests/ tests/
COPY data/ data/

RUN pip install pandas pytest

CMD ["python", "src/clean_data.py"]
```

ğŸ“Œ **Question**
Pourquoi ne pas copier tout le dÃ©pÃ´t sans distinction ?

---

### 3ï¸âƒ£ Build de lâ€™image

```bash
docker build -t dataops-pipeline .
```

---

### 4ï¸âƒ£ ExÃ©cution du pipeline

```bash
docker run --rm dataops-pipeline
```

ğŸ“Œ VÃ©rifiez que le fichier `sales_clean.csv` est bien gÃ©nÃ©rÃ©.

---

## ğŸ§ª Partie 3 â€“ Tests de qualitÃ© dans Docker

### 5ï¸âƒ£ ExÃ©cuter les tests dans le conteneur

```bash
docker run --rm dataops-pipeline pytest tests/
```

ğŸ“Œ **Question**
Pourquoi tester les donnÃ©es **dans** le conteneur ?

---

## ğŸ§ª Partie 4 â€“ Volumes Docker (donnÃ©es persistantes)

### 6ï¸âƒ£ Montage de volume

```bash
docker run --rm \
  -v $(pwd)/data:/app/data \
  dataops-pipeline
```

ğŸ“Œ **Objectif**

* SÃ©parer lâ€™environnement (conteneur)
* des donnÃ©es (volume)

---

## ğŸ§ª Partie 5 â€“ DataOps vs DevOps

| DevOps              | DataOps             |
| ------------------- | ------------------- |
| Image = application | Image = pipeline    |
| Logs applicatifs    | Logs + qualitÃ© data |
| Tests unitaires     | Tests data          |

ğŸ“Œ **Question finale**

> Pourquoi Docker est-il encore plus critique en DataOps quâ€™en DevOps ?

---

## ğŸ Conclusion

## TODO

---
