# ðŸ§ª TD DataOps â€“ Git & CI DRAFT VERSION

## **Introduction au DataOps**

---

## ðŸ§  Rappel : quâ€™est-ce que le DataOps ?

> **DataOps** consiste Ã  appliquer les principes DevOps
> (**versioning, CI/CD, qualitÃ©, automatisation**)
> aux **pipelines de donnÃ©es**.

En DataOps :

* les **donnÃ©es sont des artefacts versionnÃ©s**
* les **transformations doivent Ãªtre reproductibles**
* la **qualitÃ© des donnÃ©es est testÃ©e automatiquement**

---

## ðŸ“ Structure du projet

Vous travaillerez sur le dÃ©pÃ´t suivant :

```mermaid
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ sales.csv
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ sales_clean.csv
â”œâ”€â”€ src/
â”‚   â””â”€â”€ clean_data.py
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_data_quality.py
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml
â””â”€â”€ README.md
```

---

## ðŸ§ª Partie 1 â€“ Gitflow version DataOps

### 1ï¸âƒ£ Initialisation du dÃ©pÃ´t

* CrÃ©ez un dÃ©pÃ´t Git
* Ajoutez un fichier `sales.csv` dans `data/raw/`

Exemple de contenu :

```csv
id,product,price
1,keyboard,49.99
2,mouse,
3,screen,199.99
```

ðŸ“Œ **Question**
Pourquoi cette donnÃ©e est-elle problÃ©matique pour un pipeline data ?

---

### 2ï¸âƒ£ Gitflow adaptÃ© au DataOps

RÃ¨gles Ã  respecter :

* `main` : donnÃ©es **validÃ©es**
* `develop` : donnÃ©es en cours de prÃ©paration
* `feature/*` : transformation ou correction data

ðŸ“Œ Exemple :

```bash
git checkout -b feature/clean-sales-data
```

---

### 3ï¸âƒ£ Bonnes pratiques de commit DataOps

âŒ Mauvais commit :

```git
update data
```

âœ… Bon commit :

```git
feat(data): clean null prices in sales dataset
```

ðŸ“Œ **Consigne**

> Faites un commit expliquant clairement **ce qui change dans la donnÃ©e** et **pourquoi**.

---

## ðŸ§ª Partie 2 â€“ Transformation de donnÃ©es

### 4ï¸âƒ£ Script de nettoyage (Python)

Dans `src/clean_data.py` :

```python
import pandas as pd

df = pd.read_csv("data/raw/sales.csv")

df_clean = df.dropna()

df_clean.to_csv("data/processed/sales_clean.csv", index=False)
```

ðŸ“Œ ExÃ©cutez le script et vÃ©rifiez le fichier gÃ©nÃ©rÃ©.

---

## ðŸ§ª Partie 3 â€“ Tests de qualitÃ© de donnÃ©es

### 5ï¸âƒ£ Pourquoi tester les donnÃ©es ?

En DataOps, on teste que :

* il nâ€™y a pas de valeurs nulles
* les types sont corrects
* le volume est cohÃ©rent

---

### 6ï¸âƒ£ Test de qualitÃ© simple

Dans `tests/test_data_quality.py` :

```python
import pandas as pd

def test_no_null_values():
    df = pd.read_csv("data/processed/sales_clean.csv")
    assert df.isnull().sum().sum() == 0

def test_price_is_positive():
    df = pd.read_csv("data/processed/sales_clean.csv")
    assert (df["price"] > 0).all()
```

ðŸ“Œ **Question**

> En quoi ces tests sont-ils diffÃ©rents de tests unitaires classiques ?

---

## ðŸ§ª Partie 4 â€“ CI DataOps (GitHub Actions)

### 7ï¸âƒ£ Pipeline CI

Dans `.github/workflows/ci.yml` :

```yaml
name: DataOps CI

on: [push, pull_request]

jobs:
  data-quality:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install dependencies
        run: pip install pandas pytest

      - name: Run data transformation
        run: python src/clean_data.py

      - name: Run data quality tests
        run: pytest tests/
```

ðŸ“Œ **RÃ©sultat attendu**

* La CI Ã©choue si les donnÃ©es sont invalides
* Une PR avec une mauvaise donnÃ©e ne peut pas Ãªtre mergÃ©e

---

## ðŸ§ª Partie 5 â€“ Pull Request DataOps

### 8ï¸âƒ£ Workflow de PR

1. Travaillez dans une branche `feature/*`
2. Ouvrez une **Pull Request**
3. La CI sâ€™exÃ©cute automatiquement
4. La PR nâ€™est mergÃ©e que si :

   * les tests passent
   * la modification est justifiÃ©e

---

### 9ï¸âƒ£ Bonnes pratiques de PR DataOps

Dans la description de la PR, indiquez :

* Quelle donnÃ©e est modifiÃ©e ?
* Pourquoi ?
* Quel impact mÃ©tier ?

**Ã‡a ne vous rappel rien ? #QQOQCP**  ( Ã‡ == alt+0199 || alt+128)

ðŸ“Œ Exemple :

> Cette PR supprime les lignes avec prix nulls afin dâ€™Ã©viter des erreurs dans les calculs du chiffre dâ€™affaires.

---

## ðŸ Conclusion

> TODO
